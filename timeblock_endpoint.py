"""
Time Block Processing Endpoint
===============================
30åˆ†å˜ä½ï¼ˆã‚¿ã‚¤ãƒ ãƒ–ãƒ­ãƒƒã‚¯ï¼‰ã§ãƒ‡ãƒ¼ã‚¿ã‚’å‡¦ç†ã™ã‚‹ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ
Phase 1: Transcriptionãƒ‡ãƒ¼ã‚¿ã®ã¿
Phase 2: + SEDãƒ‡ãƒ¼ã‚¿ (behavior_summary)
Phase 3: + OpenSMILE
"""

from datetime import datetime
from typing import Optional, Dict, Any, List
import json
import traceback


def get_season(month: int) -> str:
    """æœˆã‹ã‚‰å­£ç¯€ã‚’åˆ¤å®šï¼ˆæ—¥æœ¬ã®å­£ç¯€ï¼‰"""
    if month in [3, 4, 5]:
        return "æ˜¥"
    elif month in [6, 7, 8]:
        return "å¤"
    elif month in [9, 10, 11]:
        return "ç§‹"
    else:
        return "å†¬"


def get_weekday_info(date_str: str) -> Dict[str, Any]:
    """æ—¥ä»˜æ–‡å­—åˆ—ã‹ã‚‰æ›œæ—¥æƒ…å ±ã‚’å–å¾—"""
    try:
        date_obj = datetime.strptime(date_str, "%Y-%m-%d")
        
        # æ›œæ—¥åï¼ˆæ—¥æœ¬èªï¼‰
        weekdays_ja = ["æœˆæ›œæ—¥", "ç«æ›œæ—¥", "æ°´æ›œæ—¥", "æœ¨æ›œæ—¥", "é‡‘æ›œæ—¥", "åœŸæ›œæ—¥", "æ—¥æ›œæ—¥"]
        weekday_ja = weekdays_ja[date_obj.weekday()]
        
        # é€±æœ«åˆ¤å®š
        is_weekend = date_obj.weekday() >= 5  # åœŸæ›œæ—¥(5)ã¾ãŸã¯æ—¥æ›œæ—¥(6)
        
        return {
            "weekday": weekday_ja,
            "is_weekend": is_weekend,
            "day_type": "é€±æœ«" if is_weekend else "å¹³æ—¥"
        }
    except (ValueError, TypeError):
        return {
            "weekday": "ä¸æ˜",
            "is_weekend": None,
            "day_type": "ä¸æ˜"
        }


def generate_age_context(subject_info: Optional[Dict]) -> str:
    """è¦³æ¸¬å¯¾è±¡è€…ã®åŸºæœ¬æƒ…å ±ã®ã¿ã‚’æä¾›ï¼ˆæ±ºã‚ã¤ã‘ã‚’æ’é™¤ï¼‰"""
    if not subject_info:
        return "è¦³æ¸¬å¯¾è±¡è€…æƒ…å ±ï¼šä¸æ˜"
    
    age = subject_info.get('age')
    gender = subject_info.get('gender', 'ä¸æ˜')
    notes = subject_info.get('notes', '')
    
    context_parts = []
    
    # åŸºæœ¬æƒ…å ±ã®ã¿
    if age is not None:
        context_parts.append(f"{age}æ­³ {gender}")
    else:
        context_parts.append(f"å¹´é½¢ä¸æ˜ {gender}")
    
    # å€‹åˆ¥ã®å‚™è€ƒæƒ…å ±ã‚’é‡è¦–
    if notes:
        context_parts.append(f"å‚™è€ƒï¼š{notes}")
    
    return " / ".join(context_parts)


def generate_time_context(hour: int, minute: int) -> str:
    """æ™‚åˆ»ã‚’è¡¨ç¤ºç”¨ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã§è¿”ã™"""
    return f"{hour:02d}:{minute:02d}"

async def get_whisper_data(supabase_client, device_id: str, date: str, time_block: str) -> Optional[str]:
    """
    vibe_whisperãƒ†ãƒ¼ãƒ–ãƒ«ã‹ã‚‰ç‰¹å®šã®ã‚¿ã‚¤ãƒ ãƒ–ãƒ­ãƒƒã‚¯ã®ãƒˆãƒ©ãƒ³ã‚¹ã‚¯ãƒªãƒ—ãƒˆã‚’å–å¾—
    """
    try:
        # time_blockã‚’time_blockå½¢å¼ã«å¤‰æ› (14-30 -> 14:30å½¢å¼ãªã©ã«å¯¾å¿œ)
        result = supabase_client.table('vibe_whisper').select('transcription').eq(
            'device_id', device_id
        ).eq(
            'date', date
        ).eq(
            'time_block', time_block
        ).execute()
        
        if result.data and len(result.data) > 0:
            # ã‚«ãƒ©ãƒ åã¯ 'transcription' (not 'transcript')
            return result.data[0].get('transcription', '')
        return None
    except Exception as e:
        print(f"Error fetching whisper data: {e}")
        return None


async def get_subject_info(supabase_client, device_id: str) -> Optional[Dict]:
    """
    device_idã‹ã‚‰è¦³æ¸¬å¯¾è±¡è€…æƒ…å ±ã‚’å–å¾—
    devices â†’ subjects ãƒ†ãƒ¼ãƒ–ãƒ«ã‚’çµåˆã—ã¦æƒ…å ±ã‚’å–å¾—
    """
    try:
        # ã¾ãš devices ãƒ†ãƒ¼ãƒ–ãƒ«ã‹ã‚‰ subject_id ã‚’å–å¾—
        device_result = supabase_client.table('devices').select('subject_id').eq(
            'device_id', device_id
        ).execute()
        
        if not device_result.data or len(device_result.data) == 0:
            print(f"Device not found: {device_id}")
            return None
            
        subject_id = device_result.data[0].get('subject_id')
        if not subject_id:
            print(f"No subject_id for device: {device_id}")
            return None
        
        # subjects ãƒ†ãƒ¼ãƒ–ãƒ«ã‹ã‚‰æƒ…å ±ã‚’å–å¾—
        subject_result = supabase_client.table('subjects').select(
            'subject_id', 'name', 'age', 'gender', 'notes'
        ).eq(
            'subject_id', subject_id
        ).execute()
        
        if subject_result.data and len(subject_result.data) > 0:
            return subject_result.data[0]
        
        return None
    except Exception as e:
        print(f"Error fetching subject info: {e}")
        return None

async def get_sed_data(supabase_client, device_id: str, date: str, time_block: str) -> Optional[list]:
    """
    behavior_yamnetãƒ†ãƒ¼ãƒ–ãƒ«ã‹ã‚‰ç‰¹å®šã®ã‚¿ã‚¤ãƒ ãƒ–ãƒ­ãƒƒã‚¯ã®SEDãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—
    eventsã‚«ãƒ©ãƒ ã‹ã‚‰YAMNetã®éŸ³éŸ¿ã‚¤ãƒ™ãƒ³ãƒˆæ¤œå‡ºçµæœã‚’å–å¾—
    """
    try:
        result = supabase_client.table('behavior_yamnet').select('events').eq(
            'device_id', device_id
        ).eq(
            'date', date
        ).eq(
            'time_block', time_block
        ).execute()
        
        if result.data and len(result.data) > 0:
            # eventsã¯æ—¢ã«JSONã¨ã—ã¦ãƒ‘ãƒ¼ã‚¹ã•ã‚Œã¦ã„ã‚‹ã¯ãš
            return result.data[0].get('events', [])
        return None
    except Exception as e:
        print(f"Error fetching SED data from behavior_yamnet: {e}")
        return None


async def get_opensmile_data(supabase_client, device_id: str, date: str, time_block: str) -> Optional[list]:
    """
    emotion_opensmileãƒ†ãƒ¼ãƒ–ãƒ«ã‹ã‚‰ç‰¹å®šã®ã‚¿ã‚¤ãƒ ãƒ–ãƒ­ãƒƒã‚¯ã®OpenSMILEãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—
    selected_features_timelineã‚«ãƒ©ãƒ ã‹ã‚‰éŸ³å£°ç‰¹å¾´ã®æ™‚ç³»åˆ—ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—
    """
    try:
        result = supabase_client.table('emotion_opensmile').select('selected_features_timeline').eq(
            'device_id', device_id
        ).eq(
            'date', date
        ).eq(
            'time_block', time_block
        ).execute()
        
        if result.data and len(result.data) > 0:
            # selected_features_timelineã¯æ—¢ã«JSONã¨ã—ã¦ãƒ‘ãƒ¼ã‚¹ã•ã‚Œã¦ã„ã‚‹ã¯ãš
            timeline = result.data[0].get('selected_features_timeline', [])
            # JSONæ–‡å­—åˆ—ã®å ´åˆã¯ãƒ‘ãƒ¼ã‚¹
            if isinstance(timeline, str):
                import json
                timeline = json.loads(timeline)
            return timeline
        return None
    except Exception as e:
        print(f"Error fetching OpenSMILE data from emotion_opensmile: {e}")
        return None



def generate_timeblock_prompt(transcription: Optional[str], sed_data: Optional[list], time_block: str, 
                              date: str = None, subject_info: Optional[Dict] = None, 
                              opensmile_data: Optional[list] = None) -> str:
    """
    Transcription + SEDãƒ‡ãƒ¼ã‚¿ + OpenSMILEãƒ‡ãƒ¼ã‚¿ + è¦³æ¸¬å¯¾è±¡è€…æƒ…å ±ã§ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆç”Ÿæˆ
    æ™‚ç³»åˆ—ãƒ‡ãƒ¼ã‚¿ã‚’å«ã‚€åŒ…æ‹¬çš„ãªåˆ†æã‚’ä¿ƒã™
    """
    prompt_parts = []
    
    # æ™‚é–“æƒ…å ±ã‹ã‚‰æ™‚é–“å¸¯ã‚’åˆ¤å®š
    hour = int(time_block.split('-')[0])
    minute = int(time_block.split('-')[1])
    time_context = ""
    if 5 <= hour < 9:
        time_context = "æ—©æœ"
    elif 9 <= hour < 12:
        time_context = "åˆå‰"
    elif 12 <= hour < 14:
        time_context = "æ˜¼"
    elif 14 <= hour < 17:
        time_context = "åˆå¾Œ"
    elif 17 <= hour < 20:
        time_context = "å¤•æ–¹"
    elif 20 <= hour < 23:
        time_context = "å¤œ"
    else:
        time_context = "æ·±å¤œ"
    
    # çµ‚äº†æ™‚åˆ»ã®è¨ˆç®—ï¼ˆ30åˆ†å¾Œï¼‰
    end_minute = minute + 30
    end_hour = hour
    if end_minute >= 60:
        end_hour = hour + 1
        end_minute = end_minute - 60
    
    # ==================== 1. ãƒ˜ãƒƒãƒ€ãƒ¼ï¼ˆã‚¿ã‚¹ã‚¯å®£è¨€ï¼‰ ====================
    prompt_parts.append(f"""ğŸ“Š ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«æ™‚ç³»åˆ—åˆ†æã‚¿ã‚¹ã‚¯

30åˆ†ãƒ–ãƒ­ãƒƒã‚¯ã®éŸ³å£°ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰æ„Ÿæƒ…çŠ¶æ…‹ã‚’åˆ†æã—ã€JSONå½¢å¼ã§å‡ºåŠ›ã—ã¦ãã ã•ã„ã€‚

    # ==================== 2. å‡ºåŠ›ã‚¹ã‚­ãƒ¼ãƒã¨å³æ ¼ãƒ«ãƒ¼ãƒ« ====================
    
**å‡ºåŠ›å½¢å¼ï¼ˆå¿…é ˆï¼‰:**
```json
{{
  "time_block": "{time_block}",
  "summary": "30åˆ†é–“ã®å…¨ä½“çš„ãªçŠ¶æ³ã¨æ„Ÿæƒ…ã®æµã‚Œã‚’2-3æ–‡ã§èª¬æ˜",
  "vibe_score": -36,
  "confidence_score": 0.85,
  "temporal_analysis": {{
    "emotion_trajectory": "å‰åŠã¯ç©ã‚„ã‹â†’ä¸­ç›¤ã§èˆˆå¥®â†’å¾ŒåŠã¯è½ã¡ç€ã",
    "peak_moments": ["ç‰¹å®šæ™‚åˆ»ã®æ„Ÿæƒ…ãƒ”ãƒ¼ã‚¯èª¬æ˜"],
    "quiet_periods": ["é™å¯‚æœŸé–“ã®èª¬æ˜"]
  }},
  "acoustic_features": {{
    "average_loudness": 0.186,
    "loudness_trend": "increasing/stable/decreasing",
    "voice_stability": "å®‰å®š/ã‚„ã‚„ä¸å®‰å®š/ä¸å®‰å®š",
    "notable_patterns": ["è¦³å¯Ÿã•ã‚ŒãŸéŸ³å£°ãƒ‘ã‚¿ãƒ¼ãƒ³"]
  }},
  "key_observations": [
    "æ™‚ç³»åˆ—ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰è¦³å¯Ÿã•ã‚ŒãŸé‡è¦ãªç‚¹"
  ],
  "detected_mood": "neutral/positive/negative/anxious/relaxed/excited/tired",
  "detected_activities": ["æ¨å®šã•ã‚Œã‚‹æ´»å‹•"],
  "context_notes": "è©³ç´°ãªçŠ¶æ³èª¬æ˜"
}}
```

**å³æ ¼ãƒ«ãƒ¼ãƒ«:**
- JSONã®ã¿ã‚’è¿”ã™ï¼ˆèª¬æ˜ã‚„è£œè¶³ã¯ä¸€åˆ‡ä¸è¦ï¼‰
- ã™ã¹ã¦ã®ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã¯å¿…é ˆ
- vibe_scoreã¯å¿…ãš-100ã€œ+100ã®æ•´æ•°å€¤
- confidence_scoreã¯0.0ã€œ1.0ã®å°æ•°å€¤

    # ==================== 3. åˆ†æã®å‰ææ¡ä»¶ã¨åˆ¶ç´„ï¼ˆæœ€é‡è¦ï¼‰ ====================
    
**è¦³æ¸¬å¯¾è±¡è€…ã®ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒªãƒ³ã‚°:**
{generate_age_context(subject_info)}

**åˆ†æã®å„ªå…ˆé †ä½ï¼ˆå³å®ˆï¼‰:**
1. ç¬¬1å„ªå…ˆ: ç™ºè©±å†…å®¹ã¨è¦³æ¸¬å¯¾è±¡è€…ã®å¹´é½¢ãƒ»ç‰¹æ€§ã®ç…§åˆ
2. ç¬¬2å„ªå…ˆ: æ™‚é–“å¸¯ãƒ»å­£ç¯€ã¨ã®æ•´åˆæ€§ç¢ºèª
3. ç¬¬3å„ªå…ˆ: éŸ³éŸ¿ç‰¹å¾´ï¼ˆè£œå®Œçš„ã«ä½¿ç”¨ã€ä¸»åˆ¤æ–­ã‚’è¦†ã™ã«ã¯å¼·ã„æ ¹æ‹ ãŒå¿…è¦ï¼‰

**èª¤è§£æé˜²æ­¢ã®é‰„å‰‡:**
- å­ä¾›ã®æ¼”æŠ€çš„ç™ºè©±ãƒ»ã”ã£ã“éŠã³ â†’ å¹´é½¢ç›¸å¿œã®æ­£å¸¸ãªç™ºé”è¡Œå‹•ã¨ã—ã¦è©•ä¾¡
- ç‹¬ã‚Šè¨€ãƒ»è‡ªå·±å¯¾è©± â†’ å¹¼å…ã€œå­¦ç«¥æœŸã§ã¯æ­£å¸¸ï¼ˆã‚€ã—ã‚èªçŸ¥ç™ºé”ã®è¨¼ï¼‰
- æ™‚é–“å¸¯ã®ã¿ã§ã®ç•°å¸¸åˆ¤å®š â†’ ç¦æ­¢ï¼ˆå€‹äººã®ç”Ÿæ´»ãƒªã‚ºãƒ ã‚’å°Šé‡ï¼‰
- æ„Ÿæƒ…ã®èµ·ä¼ â†’ å¹´é½¢ãƒ»çŠ¶æ³ã‚’è€ƒæ…®ï¼ˆå­ä¾›ã¯æ„Ÿæƒ…è¡¨ç¾ãŒè±Šã‹ï¼‰

**ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚’è¸ã¾ãˆãŸè§£é‡ˆ:**
- 5æ­³å…ãŒæ€ªç£ã”ã£ã“ã§å«ã¶ â†’ ãƒã‚¸ãƒ†ã‚£ãƒ–ãªéŠã³ï¼ˆãƒã‚¬ãƒ†ã‚£ãƒ–åˆ¤å®šã—ãªã„ï¼‰
- å¤•æ–¹ã®é¨’ãŒã—ã• â†’ å­ä¾›ã®æ´»å‹•æ™‚é–“ã¨ã—ã¦æ­£å¸¸
- å¤§äººã®ç‹¬ã‚Šè¨€ â†’ ã‚¹ãƒˆãƒ¬ã‚¹å‡¦ç†ã®å¯èƒ½æ€§ï¼ˆå¿…ãšã—ã‚‚ãƒã‚¬ãƒ†ã‚£ãƒ–ã§ã¯ãªã„ï¼‰

    # ==================== 4. æ¡ç‚¹ãƒ»ã‚¹ã‚³ã‚¢åˆ†å¸ƒãƒãƒªã‚·ãƒ¼ ====================
    
**vibe_scoreã®æ¡ç‚¹åŸºæº–:**
- **-100ã€œ+100ã®å…¨ç¯„å›²ã‚’ç©æ¥µçš„ã«ä½¿ç”¨**
- ã‚¹ã‚³ã‚¢åˆ†å¸ƒï¼š
  * éå¸¸ã«ãƒã‚¸ãƒ†ã‚£ãƒ–: 60ã€œ100
  * ãƒã‚¸ãƒ†ã‚£ãƒ–: 20ã€œ60
  * ãƒ‹ãƒ¥ãƒ¼ãƒˆãƒ©ãƒ«: -20ã€œ20
  * ãƒã‚¬ãƒ†ã‚£ãƒ–: -60ã€œ-20
  * éå¸¸ã«ãƒã‚¬ãƒ†ã‚£ãƒ–: -100ã€œ-60

**æ¡ç‚¹è¦ç´ ï¼ˆè¦³æ¸¬å¯¾è±¡è€…ã®å¹´é½¢ã‚’è€ƒæ…®ã—ã¦èª¿æ•´ï¼‰:**
- éŸ³é‡ãŒå¤§ãã„æ™‚é–“å¸¯: +10ã€œ20ï¼ˆå­ä¾›ã®å ´åˆã¯æ­£å¸¸ç¯„å›²ï¼‰
- å£°ã®éœ‡ãˆãŒå¤šã„: -10ã€œ30ï¼ˆçŠ¶æ³ã¨å¹´é½¢ã«ã‚ˆã‚‹ï¼‰
- é•·ã„æ²ˆé»™: -5ã€œ15ï¼ˆé›†ä¸­ã‚„ä¼‘æ¯ã®å¯èƒ½æ€§ã‚‚è€ƒæ…®ï¼‰
- æ´»ç™ºãªä¼šè©±: +15ã€œ25
- æ—©æœã®æ´»å‹•: +20ã€œ30ï¼ˆå¹´é½¢ã«ã‚ˆã‚Šåˆ¤æ–­ï¼‰
- æ·±å¤œã®æ´»å‹•: -20ã€œ30ï¼ˆå€‹äººå·®ã‚’è€ƒæ…®ï¼‰

**confidence_scoreã®æ±ºå®šåŸºæº–:**
- ãƒ‡ãƒ¼ã‚¿ã®å®Œå…¨æ€§ï¼ˆå…¨ãƒ¢ãƒ€ãƒªãƒ†ã‚£ãŒæƒã£ã¦ã„ã‚‹ï¼‰: 0.8ã€œ1.0
- éƒ¨åˆ†çš„ãƒ‡ãƒ¼ã‚¿: 0.4ã€œ0.8
- å˜ä¸€ãƒ¢ãƒ€ãƒªãƒ†ã‚£ã®ã¿: 0.2ã€œ0.4

    # ==================== 5. ãƒ¡ã‚¿æƒ…å ± ====================
    
    # æ›œæ—¥æƒ…å ±ã‚’å–å¾—
    weekday_info = get_weekday_info(date) if date else {"weekday": "ä¸æ˜", "day_type": "ä¸æ˜"}
    
    prompt_parts.append(f"""ã€åˆ†æå¯¾è±¡ã€‘
- åœ°åŸŸ: æ—¥æœ¬
- å­£ç¯€: {get_season(int(date.split('-')[1])) if date else 'ä¸æ˜'}
- æ—¥ä»˜: {date if date else 'ä¸æ˜'}
- æ›œæ—¥: {weekday_info['weekday']}ï¼ˆ{weekday_info['day_type']}ï¼‰
- æ™‚åˆ»: {generate_time_context(hour, minute)}
- æ™‚é–“ç¯„å›²: {hour:02d}:{minute:02d}ã€œ{end_hour:02d}:{end_minute:02d}ï¼ˆ30åˆ†ãƒ–ãƒ­ãƒƒã‚¯ï¼‰
""")
    
    # è¦³æ¸¬å¯¾è±¡è€…æƒ…å ±ã‚’ãƒ¡ã‚¿æƒ…å ±ã«å«ã‚ã‚‹
    if subject_info:
        subject_parts = []
        if subject_info.get('name'):
            subject_parts.append(f"åå‰: {subject_info['name']}")
        if subject_info.get('age') is not None:
            subject_parts.append(f"å¹´é½¢: {subject_info['age']}æ­³")
        if subject_info.get('gender'):
            subject_parts.append(f"æ€§åˆ¥: {subject_info['gender']}")
        if subject_info.get('notes'):
            subject_parts.append(f"å‚™è€ƒ: {subject_info['notes']}")
        
        prompt_parts.append("- è¦³æ¸¬å¯¾è±¡è€…: " + ", ".join(subject_parts) + "\n")
    else:
        prompt_parts.append("- è¦³æ¸¬å¯¾è±¡è€…: æƒ…å ±ãªã—\n")
    
    # ==================== 6. è¦ç´„çµ±è¨ˆ ====================
    prompt_parts.append("\nã€è¦ç´„çµ±è¨ˆã€‘\n")
    
    # ç™ºè©±ã®è¦ç´„
    if transcription and transcription.strip():
        prompt_parts.append(f"â—† ç™ºè©±: ã‚ã‚Šï¼ˆ{len(transcription)}æ–‡å­—ï¼‰")
    else:
        prompt_parts.append("â—† ç™ºè©±: ãªã—ï¼ˆéŒ²éŸ³ã¯ã•ã‚ŒãŸãŒè¨€èªçš„ãªæƒ…å ±ãªã—ï¼‰")
    
    # OpenSMILEã®çµ±è¨ˆæƒ…å ±ã‚’å…ˆã«è¨ˆç®—
    if opensmile_data and len(opensmile_data) > 0:
        loudness_values = [item.get('features', {}).get('Loudness_sma3', 0) for item in opensmile_data]
        jitter_values = [item.get('features', {}).get('jitterLocal_sma3nz', 0) for item in opensmile_data]
        
        avg_loudness = sum(loudness_values) / len(loudness_values)
        max_loudness = max(loudness_values)
        min_loudness = min(loudness_values)
        avg_jitter = sum(jitter_values) / len(jitter_values)
        max_jitter = max(jitter_values)
        
        prompt_parts.append(f"""â—† éŸ³å£°ç‰¹å¾´ï¼ˆOpenSMILEï¼‰çµ±è¨ˆ:
  - è¨˜éŒ²æ™‚é–“: {len(opensmile_data)}ç§’
  - å¹³å‡éŸ³é‡: {avg_loudness:.3f} (ç¯„å›²: {min_loudness:.3f}ã€œ{max_loudness:.3f})
  - å¹³å‡å£°ã®éœ‡ãˆ: {avg_jitter:.6f} (æœ€å¤§: {max_jitter:.6f})
  - ç„¡éŸ³åŒºé–“: {jitter_values.count(0)}ç§’ / {len(jitter_values)}ç§’""")
    else:
        prompt_parts.append("â—† éŸ³å£°ç‰¹å¾´ï¼ˆOpenSMILEï¼‰: ãƒ‡ãƒ¼ã‚¿ãªã—")
    
    # SEDãƒ‡ãƒ¼ã‚¿ï¼ˆéŸ³éŸ¿ã‚¤ãƒ™ãƒ³ãƒˆï¼‰ã®çµ±è¨ˆ
    if sed_data:
        # ç¢ºç‡ã®é«˜ã„ä¸Šä½ã‚¤ãƒ™ãƒ³ãƒˆã‚’æŠ½å‡º
        sorted_events = sorted(sed_data, key=lambda x: x.get('prob', 0), reverse=True)
        
        # ä¸»è¦ãªéŸ³éŸ¿ã‚¤ãƒ™ãƒ³ãƒˆã®çµ±è¨ˆ
        high_prob_events = [e for e in sorted_events if e.get('prob', 0) >= 0.7]
        mid_prob_events = [e for e in sorted_events if 0.4 <= e.get('prob', 0) < 0.7]
        
        speech_prob = next((e.get('prob', 0)*100 for e in sorted_events if 'Speech' in e.get('label', '')), 0)
        has_child_voice = any('Child' in e.get('label', '') or 'Baby' in e.get('label', '') for e in sorted_events[:20])
        has_noise = any('Noise' in e.get('label', '') for e in sorted_events[:10])
        activity_diversity = len([e for e in sorted_events[:20] if e.get('prob', 0) > 0.3])
        
        prompt_parts.append(f"""â—† éŸ³éŸ¿ã‚¤ãƒ™ãƒ³ãƒˆï¼ˆYAMNetï¼‰çµ±è¨ˆ:
  - æ¤œå‡ºã‚¤ãƒ™ãƒ³ãƒˆç·æ•°: {len(sed_data)}ç¨®é¡
  - é«˜ç¢ºç‡ã‚¤ãƒ™ãƒ³ãƒˆï¼ˆ70%ä»¥ä¸Šï¼‰: {len(high_prob_events)}å€‹
  - ä¸­ç¢ºç‡ã‚¤ãƒ™ãƒ³ãƒˆï¼ˆ40-70%ï¼‰: {len(mid_prob_events)}å€‹
  - Speechæ¤œå‡ºç‡: {speech_prob:.1f}%
  - å­ä¾›ã®å£°: {'æ¤œå‡º' if has_child_voice else 'æœªæ¤œå‡º'}
  - ç’°å¢ƒãƒã‚¤ã‚º: {'é«˜' if has_noise else 'ä½'}
  - æ´»å‹•éŸ³ã®å¤šæ§˜æ€§: {activity_diversity}ç¨®é¡""")
    else:
        prompt_parts.append("â—† éŸ³éŸ¿ã‚¤ãƒ™ãƒ³ãƒˆï¼ˆYAMNetï¼‰: ãƒ‡ãƒ¼ã‚¿ãªã—")
    
    
    # ==================== 7. è©³ç´°ãƒ‡ãƒ¼ã‚¿ ====================
    prompt_parts.append("\n\nã€è©³ç´°ãƒ‡ãƒ¼ã‚¿ã€‘\n")
    
    # ç™ºè©±å†…å®¹ã®è©³ç´°
    if transcription and transcription.strip():
        prompt_parts.append(f"""â—† ç™ºè©±å†…å®¹ï¼ˆå…¨æ–‡ï¼‰:
{transcription}
""")
    
    # OpenSMILEã®æ™‚ç³»åˆ—ãƒ‡ãƒ¼ã‚¿ï¼ˆè©³ç´°ï¼‰
    if opensmile_data and len(opensmile_data) > 0:
        prompt_parts.append("â—† éŸ³å£°ç‰¹å¾´ã®æ™‚ç³»åˆ—ï¼ˆOpenSMILEã€1ç§’æ¯ï¼‰:")
        prompt_parts.append("æ™‚åˆ» | éŸ³é‡(Loudness) | å£°ã®éœ‡ãˆ(Jitter)")
        prompt_parts.append("-----|---------------|----------------")
        
        for item in opensmile_data[:60]:  # æœ€å¤§60ç§’åˆ†
            timestamp = item.get('timestamp', 'N/A')
            features = item.get('features', {})
            loudness = features.get('Loudness_sma3', 0)
            jitter = features.get('jitterLocal_sma3nz', 0)
            prompt_parts.append(f"{timestamp} | {loudness:.3f} | {jitter:.6f}")
    
    # SEDã‚¤ãƒ™ãƒ³ãƒˆã®è©³ç´°ãƒªã‚¹ãƒˆ
    if sed_data:
        sorted_events = sorted(sed_data, key=lambda x: x.get('prob', 0), reverse=True)
        prompt_parts.append("\nâ—† éŸ³éŸ¿ã‚¤ãƒ™ãƒ³ãƒˆè©³ç´°ï¼ˆYAMNetã€ç¢ºç‡é †ï¼‰:")
        
        # ä¸Šä½20å€‹ã®ã‚¤ãƒ™ãƒ³ãƒˆã®ã¿è¡¨ç¤º
        for i, event in enumerate(sorted_events[:20], 1):
            label = event.get('label', 'Unknown')
            prob = event.get('prob', 0)
            prompt_parts.append(f"  {i}. {label}: {prob*100:.1f}%")
    
    return "\n".join(prompt_parts)


async def update_whisper_status(supabase_client, device_id: str, date: str, time_block: str):
    """
    vibe_whisperãƒ†ãƒ¼ãƒ–ãƒ«ã®statusã‚’completedã«æ›´æ–°
    """
    try:
        data = {
            'status': 'completed'
        }
        
        result = supabase_client.table('vibe_whisper').update(data).eq(
            'device_id', device_id
        ).eq(
            'date', date
        ).eq(
            'time_block', time_block
        ).execute()
        
        print(f"âœ… Updated vibe_whisper status to completed for {time_block}")
        return True
    except Exception as e:
        print(f"âš ï¸ Error updating vibe_whisper status: {e}")
        return False


async def update_yamnet_status(supabase_client, device_id: str, date: str, time_block: str):
    """
    behavior_yamnetãƒ†ãƒ¼ãƒ–ãƒ«ã®statusã‚’completedã«æ›´æ–°
    """
    try:
        data = {
            'status': 'completed'
        }
        
        result = supabase_client.table('behavior_yamnet').update(data).eq(
            'device_id', device_id
        ).eq(
            'date', date
        ).eq(
            'time_block', time_block
        ).execute()
        
        print(f"âœ… Updated behavior_yamnet status to completed for {time_block}")
        return True
    except Exception as e:
        print(f"âš ï¸ Error updating behavior_yamnet status: {e}")
        return False


async def update_opensmile_status(supabase_client, device_id: str, date: str, time_block: str):
    """
    emotion_opensmileãƒ†ãƒ¼ãƒ–ãƒ«ã®statusã‚’completedã«æ›´æ–°
    """
    try:
        data = {
            'status': 'completed'
        }
        
        result = supabase_client.table('emotion_opensmile').update(data).eq(
            'device_id', device_id
        ).eq(
            'date', date
        ).eq(
            'time_block', time_block
        ).execute()
        
        print(f"âœ… Updated emotion_opensmile status to completed for {time_block}")
        return True
    except Exception as e:
        print(f"âš ï¸ Error updating emotion_opensmile status: {e}")
        return False


async def save_prompt_to_dashboard(supabase_client, device_id: str, date: str, time_block: str, prompt: str):
    """
    ç”Ÿæˆã—ãŸãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’dashboardãƒ†ãƒ¼ãƒ–ãƒ«ã«ä¿å­˜
    """
    try:
        data = {
            'device_id': device_id,
            'date': date,
            'time_block': time_block,
            'prompt': prompt,
            'updated_at': datetime.now().isoformat()
        }
        
        result = supabase_client.table('dashboard').upsert(data).execute()
        print(f"âœ… Prompt saved to dashboard table for {time_block}")
        return True
    except Exception as e:
        print(f"Error saving prompt to dashboard: {e}")
        traceback.print_exc()
        return False


async def process_and_save_to_dashboard(supabase_client, device_id: str, date: str, time_block: str, 
                                       summary: str = None, vibe_score: float = None):
    """
    å‡¦ç†çµæœã‚’dashboardãƒ†ãƒ¼ãƒ–ãƒ«ã«ä¿å­˜
    """
    try:
        data = {
            'device_id': device_id,
            'date': date,
            'time_block': time_block,
            'updated_at': datetime.now().isoformat()
        }
        
        # NULLã‚’è¨±å¯ã™ã‚‹ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã¯å€¤ãŒã‚ã‚‹å ´åˆã®ã¿è¿½åŠ 
        if summary is not None:
            data['summary'] = summary
        if vibe_score is not None:
            data['vibe_score'] = vibe_score
        
        result = supabase_client.table('dashboard').upsert(data).execute()
        return True
    except Exception as e:
        print(f"Error saving to dashboard: {e}")
        traceback.print_exc()
        return False


# ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆç”¨ã®å‡¦ç†é–¢æ•°


async def process_timeblock_v2(supabase_client, device_id: str, date: str, time_block: str) -> Dict[str, Any]:
    """
    å‡¦ç†: Whisper + SEDãƒ‡ãƒ¼ã‚¿ï¼ˆbehavior_yamnetãƒ†ãƒ¼ãƒ–ãƒ«ä½¿ç”¨ï¼‰+ OpenSMILEãƒ‡ãƒ¼ã‚¿ + è¦³æ¸¬å¯¾è±¡è€…æƒ…å ±
    ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆç”Ÿæˆå¾Œã€ä½¿ç”¨ã•ã‚ŒãŸãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹ã®statusã‚’completedã«æ›´æ–°
    """
    # ãƒ‡ãƒ¼ã‚¿å–å¾—
    transcription = await get_whisper_data(supabase_client, device_id, date, time_block)
    sed_data = await get_sed_data(supabase_client, device_id, date, time_block)
    opensmile_data = await get_opensmile_data(supabase_client, device_id, date, time_block)
    subject_info = await get_subject_info(supabase_client, device_id)
    
    # ãƒ‡ãƒ¼ã‚¿å­˜åœ¨ãƒ•ãƒ©ã‚°ã‚’è¨˜éŒ²
    has_whisper = transcription is not None
    has_yamnet = sed_data is not None and len(sed_data) > 0
    has_opensmile = opensmile_data is not None and len(opensmile_data) > 0
    
    # ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆç”Ÿæˆï¼ˆOpenSMILEãƒ‡ãƒ¼ã‚¿ã‚‚å«ã‚ã¦æ¸¡ã™ï¼‰
    prompt = generate_timeblock_prompt(transcription, sed_data, time_block, date, subject_info, opensmile_data)
    
    # ãƒ‡ãƒãƒƒã‚°ç”¨ï¼šå–å¾—ã—ãŸãƒ‡ãƒ¼ã‚¿ã®æƒ…å ±ã‚’å‡ºåŠ›
    print(f"ğŸ“Š Data retrieved for {time_block}:")
    print(f"  - Transcription: {'Yes' if has_whisper else 'No'} ({len(transcription) if transcription else 0} chars)")
    print(f"  - SED Events: {'Yes' if has_yamnet else 'No'} ({len(sed_data) if sed_data else 0} events)")
    print(f"  - OpenSMILE Timeline: {'Yes' if has_opensmile else 'No'} ({len(opensmile_data) if opensmile_data else 0} seconds)")
    print(f"  - Subject Info: {'Yes' if subject_info else 'No'}")
    
    # ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆä¿å­˜ï¼ˆdashboardãƒ†ãƒ¼ãƒ–ãƒ«ã¸ï¼‰
    dashboard_saved = await save_prompt_to_dashboard(supabase_client, device_id, date, time_block, prompt)
    
    # dashboardã¸ã®ä¿å­˜ãŒæˆåŠŸã—ãŸå ´åˆã®ã¿ã€å„ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹ã®statusã‚’æ›´æ–°
    status_updates = {
        "whisper_updated": False,
        "yamnet_updated": False,
        "opensmile_updated": False
    }
    
    if dashboard_saved:
        print(f"\nğŸ“ Updating status for used data sources...")
        
        # å®Ÿéš›ã«ãƒ‡ãƒ¼ã‚¿ãŒå­˜åœ¨ã—ãŸå ´åˆã®ã¿statusã‚’æ›´æ–°
        if has_whisper:
            status_updates["whisper_updated"] = await update_whisper_status(
                supabase_client, device_id, date, time_block
            )
        
        if has_yamnet:
            status_updates["yamnet_updated"] = await update_yamnet_status(
                supabase_client, device_id, date, time_block
            )
        
        if has_opensmile:
            status_updates["opensmile_updated"] = await update_opensmile_status(
                supabase_client, device_id, date, time_block
            )
        
        # æ›´æ–°çµæœã®ã‚µãƒãƒªãƒ¼
        print(f"\nâœ¨ Status update summary:")
        print(f"  - vibe_whisper: {'âœ… Updated' if status_updates['whisper_updated'] else 'â­ï¸ Skipped (no data)' if not has_whisper else 'âš ï¸ Update failed'}")
        print(f"  - behavior_yamnet: {'âœ… Updated' if status_updates['yamnet_updated'] else 'â­ï¸ Skipped (no data)' if not has_yamnet else 'âš ï¸ Update failed'}")
        print(f"  - emotion_opensmile: {'âœ… Updated' if status_updates['opensmile_updated'] else 'â­ï¸ Skipped (no data)' if not has_opensmile else 'âš ï¸ Update failed'}")
    else:
        print(f"âš ï¸ Dashboard save failed, skipping status updates")
    
    return {
        "status": "success",
        "version": "v3",  # ãƒãƒ¼ã‚¸ãƒ§ãƒ³ã‚’v3ã«æ›´æ–°
        "device_id": device_id,
        "date": date,
        "time_block": time_block,
        "prompt": prompt,  # ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’è¿”ã‚Šå€¤ã«è¿½åŠ 
        "prompt_length": len(prompt),
        "has_transcription": has_whisper and len(transcription.strip()) > 0,
        "has_sed_data": has_yamnet,
        "has_opensmile_data": has_opensmile,
        "sed_events_count": len(sed_data) if sed_data else 0,
        "opensmile_seconds": len(opensmile_data) if opensmile_data else 0,
        "dashboard_saved": dashboard_saved,
        "status_updates": status_updates
    }