"""
Time Block Processing Endpoint
===============================
30åˆ†å˜ä½ï¼ˆã‚¿ã‚¤ãƒ ãƒ–ãƒ­ãƒƒã‚¯ï¼‰ã§ãƒ‡ãƒ¼ã‚¿ã‚’å‡¦ç†ã™ã‚‹ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ
Phase 1: Transcriptionãƒ‡ãƒ¼ã‚¿ã®ã¿
Phase 2: + SEDãƒ‡ãƒ¼ã‚¿ (behavior_summary)
Phase 3: + OpenSMILE
"""

from datetime import datetime
from typing import Optional, Dict, Any, List
import json
import traceback

async def get_whisper_data(supabase_client, device_id: str, date: str, time_block: str) -> Optional[str]:
    """
    vibe_whisperãƒ†ãƒ¼ãƒ–ãƒ«ã‹ã‚‰ç‰¹å®šã®ã‚¿ã‚¤ãƒ ãƒ–ãƒ­ãƒƒã‚¯ã®ãƒˆãƒ©ãƒ³ã‚¹ã‚¯ãƒªãƒ—ãƒˆã‚’å–å¾—
    """
    try:
        # time_blockã‚’time_blockå½¢å¼ã«å¤‰æ› (14-30 -> 14:30å½¢å¼ãªã©ã«å¯¾å¿œ)
        result = supabase_client.table('vibe_whisper').select('transcription').eq(
            'device_id', device_id
        ).eq(
            'date', date
        ).eq(
            'time_block', time_block
        ).execute()
        
        if result.data and len(result.data) > 0:
            # ã‚«ãƒ©ãƒ åã¯ 'transcription' (not 'transcript')
            return result.data[0].get('transcription', '')
        return None
    except Exception as e:
        print(f"Error fetching whisper data: {e}")
        return None


async def get_subject_info(supabase_client, device_id: str) -> Optional[Dict]:
    """
    device_idã‹ã‚‰è¦³æ¸¬å¯¾è±¡è€…æƒ…å ±ã‚’å–å¾—
    devices â†’ subjects ãƒ†ãƒ¼ãƒ–ãƒ«ã‚’çµåˆã—ã¦æƒ…å ±ã‚’å–å¾—
    """
    try:
        # ã¾ãš devices ãƒ†ãƒ¼ãƒ–ãƒ«ã‹ã‚‰ subject_id ã‚’å–å¾—
        device_result = supabase_client.table('devices').select('subject_id').eq(
            'device_id', device_id
        ).execute()
        
        if not device_result.data or len(device_result.data) == 0:
            print(f"Device not found: {device_id}")
            return None
            
        subject_id = device_result.data[0].get('subject_id')
        if not subject_id:
            print(f"No subject_id for device: {device_id}")
            return None
        
        # subjects ãƒ†ãƒ¼ãƒ–ãƒ«ã‹ã‚‰æƒ…å ±ã‚’å–å¾—
        subject_result = supabase_client.table('subjects').select(
            'subject_id', 'name', 'age', 'gender', 'notes'
        ).eq(
            'subject_id', subject_id
        ).execute()
        
        if subject_result.data and len(subject_result.data) > 0:
            return subject_result.data[0]
        
        return None
    except Exception as e:
        print(f"Error fetching subject info: {e}")
        return None

async def get_sed_data(supabase_client, device_id: str, date: str, time_block: str) -> Optional[list]:
    """
    behavior_yamnetãƒ†ãƒ¼ãƒ–ãƒ«ã‹ã‚‰ç‰¹å®šã®ã‚¿ã‚¤ãƒ ãƒ–ãƒ­ãƒƒã‚¯ã®SEDãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—
    eventsã‚«ãƒ©ãƒ ã‹ã‚‰YAMNetã®éŸ³éŸ¿ã‚¤ãƒ™ãƒ³ãƒˆæ¤œå‡ºçµæœã‚’å–å¾—
    """
    try:
        result = supabase_client.table('behavior_yamnet').select('events').eq(
            'device_id', device_id
        ).eq(
            'date', date
        ).eq(
            'time_block', time_block
        ).execute()
        
        if result.data and len(result.data) > 0:
            # eventsã¯æ—¢ã«JSONã¨ã—ã¦ãƒ‘ãƒ¼ã‚¹ã•ã‚Œã¦ã„ã‚‹ã¯ãš
            return result.data[0].get('events', [])
        return None
    except Exception as e:
        print(f"Error fetching SED data from behavior_yamnet: {e}")
        return None


async def get_opensmile_data(supabase_client, device_id: str, date: str, time_block: str) -> Optional[list]:
    """
    emotion_opensmileãƒ†ãƒ¼ãƒ–ãƒ«ã‹ã‚‰ç‰¹å®šã®ã‚¿ã‚¤ãƒ ãƒ–ãƒ­ãƒƒã‚¯ã®OpenSMILEãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—
    selected_features_timelineã‚«ãƒ©ãƒ ã‹ã‚‰éŸ³å£°ç‰¹å¾´ã®æ™‚ç³»åˆ—ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—
    """
    try:
        result = supabase_client.table('emotion_opensmile').select('selected_features_timeline').eq(
            'device_id', device_id
        ).eq(
            'date', date
        ).eq(
            'time_block', time_block
        ).execute()
        
        if result.data and len(result.data) > 0:
            # selected_features_timelineã¯æ—¢ã«JSONã¨ã—ã¦ãƒ‘ãƒ¼ã‚¹ã•ã‚Œã¦ã„ã‚‹ã¯ãš
            timeline = result.data[0].get('selected_features_timeline', [])
            # JSONæ–‡å­—åˆ—ã®å ´åˆã¯ãƒ‘ãƒ¼ã‚¹
            if isinstance(timeline, str):
                import json
                timeline = json.loads(timeline)
            return timeline
        return None
    except Exception as e:
        print(f"Error fetching OpenSMILE data from emotion_opensmile: {e}")
        return None



def generate_timeblock_prompt(transcription: Optional[str], sed_data: Optional[list], time_block: str, 
                              date: str = None, subject_info: Optional[Dict] = None, 
                              opensmile_data: Optional[list] = None) -> str:
    """
    Transcription + SEDãƒ‡ãƒ¼ã‚¿ + OpenSMILEãƒ‡ãƒ¼ã‚¿ + è¦³æ¸¬å¯¾è±¡è€…æƒ…å ±ã§ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆç”Ÿæˆ
    æ™‚ç³»åˆ—ãƒ‡ãƒ¼ã‚¿ã‚’å«ã‚€åŒ…æ‹¬çš„ãªåˆ†æã‚’ä¿ƒã™
    """
    prompt_parts = []
    
    # æ™‚é–“æƒ…å ±ã‹ã‚‰æ™‚é–“å¸¯ã‚’åˆ¤å®š
    hour = int(time_block.split('-')[0])
    time_context = ""
    if 5 <= hour < 9:
        time_context = "æ—©æœ"
    elif 9 <= hour < 12:
        time_context = "åˆå‰"
    elif 12 <= hour < 14:
        time_context = "æ˜¼"
    elif 14 <= hour < 17:
        time_context = "åˆå¾Œ"
    elif 17 <= hour < 20:
        time_context = "å¤•æ–¹"
    elif 20 <= hour < 23:
        time_context = "å¤œ"
    else:
        time_context = "æ·±å¤œ"
    
    # ãƒ˜ãƒƒãƒ€ãƒ¼
    prompt_parts.append(f"""ğŸ“Š è¦³æ¸¬å¯¾è±¡è€…ã®è¡Œå‹•ãƒ»æ„Ÿæƒ…åˆ†æ

30åˆ†å˜ä½ã§è¨˜éŒ²ã•ã‚ŒãŸ60ç§’é–“ã®éŸ³å£°ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰ã€è¦³æ¸¬å¯¾è±¡è€…ã®æ§˜å­ã‚’åˆ†æã—ã¦ãã ã•ã„ã€‚

ã€è¨˜éŒ²æ™‚é–“ã€‘
{date if date else ''}ã®{time_block.replace('-', ':')}ï¼ˆ{time_context}ï¼‰
â€»30åˆ†æ å†…ã®60ç§’é–“ã®è¨˜éŒ²

ã€åˆ†æã®é‡ç‚¹ã€‘
- ç™ºè©±å†…å®¹ã‚’æœ€é‡è¦–ã—ã€ä½•ã‚’ã—ã¦ã„ãŸã‹ã€ã©ã‚“ãªæ°—æŒã¡ã ã£ãŸã‹ã‚’æ¨æ¸¬
- å£°ã®å¤‰åŒ–ãƒ‘ã‚¿ãƒ¼ãƒ³ã‹ã‚‰å ´ã®ç››ã‚Šä¸ŠãŒã‚Šã‚„ãƒ†ãƒ³ã‚·ãƒ§ãƒ³ã‚’åˆ¤æ–­
- ç’°å¢ƒéŸ³ã‹ã‚‰æ´»å‹•å†…å®¹ã‚’è£œå®Œçš„ã«æ¨æ¸¬
""")
    
    # è¦³æ¸¬å¯¾è±¡è€…æƒ…å ±
    if subject_info:
        subject_parts = []
        subject_parts.append("ã€è¦³æ¸¬å¯¾è±¡è€…æƒ…å ±ã€‘")
        if subject_info.get('name'):
            subject_parts.append(f"- åå‰: {subject_info['name']}")
        if subject_info.get('age') is not None:
            subject_parts.append(f"- å¹´é½¢: {subject_info['age']}æ­³")
        if subject_info.get('gender'):
            subject_parts.append(f"- æ€§åˆ¥: {subject_info['gender']}")
        if subject_info.get('notes'):
            subject_parts.append(f"- å‚™è€ƒ: {subject_info['notes']}")
        
        prompt_parts.append("\n".join(subject_parts) + "\n")
    else:
        prompt_parts.append("ã€è¦³æ¸¬å¯¾è±¡è€…æƒ…å ±ã€‘\næƒ…å ±ãªã—\n")
    
    # ãƒˆãƒ©ãƒ³ã‚¹ã‚¯ãƒªãƒ—ã‚·ãƒ§ãƒ³
    if transcription and transcription.strip():
        prompt_parts.append(f"""
ã€ç™ºè©±å†…å®¹ã€‘
{transcription}
""")
    else:
        prompt_parts.append("""ã€ç™ºè©±å†…å®¹ã€‘
(ç™ºè©±ãªã—) - éŒ²éŸ³ã¯ã•ã‚ŒãŸãŒè¨€èªçš„ãªæƒ…å ±ãªã—
""")
    
    # OpenSMILEãƒ‡ãƒ¼ã‚¿ï¼ˆéŸ³å£°ç‰¹å¾´ã®æ™‚ç³»åˆ—ï¼‰
    if opensmile_data:
        prompt_parts.append("""
ã€60ç§’é–“ã®å£°ã®å¤‰åŒ–ãƒ‘ã‚¿ãƒ¼ãƒ³ã€‘
â€»1ç§’æ¯ã®éŸ³å£°ã®å¤‰åŒ–ã‚’è¨˜éŒ²ã—ã¦ã„ã¾ã™ã€‚å¤‰åŒ–ãƒ‘ã‚¿ãƒ¼ãƒ³ã‹ã‚‰å ´ã®ç››ã‚Šä¸ŠãŒã‚Šã‚„ãƒ†ãƒ³ã‚·ãƒ§ãƒ³ã‚’åˆ¤æ–­ã—ã¦ãã ã•ã„ã€‚
""")
        
        # æ™‚ç³»åˆ—ãƒ‡ãƒ¼ã‚¿ã‚’è¡¨å½¢å¼ã§è¡¨ç¤º
        timeline_parts = []
        timeline_parts.append("æ™‚åˆ» | éŸ³é‡(Loudness) | å£°ã®éœ‡ãˆ(Jitter) | è§£é‡ˆã®ãƒ’ãƒ³ãƒˆ")
        timeline_parts.append("-----|---------------|-----------------|-------------")
        
        for i, item in enumerate(opensmile_data[:60]):  # æœ€å¤§60ç§’åˆ†
            timestamp = item.get('timestamp', 'N/A')
            features = item.get('features', {})
            loudness = features.get('Loudness_sma3', 0)
            jitter = features.get('jitterLocal_sma3nz', 0)
            
            # è§£é‡ˆã®ãƒ’ãƒ³ãƒˆã‚’è¿½åŠ ï¼ˆå¤‰åŒ–ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’é‡è¦–ï¼‰
            hint = ""
            # å‰ã®å€¤ã¨ã®æ¯”è¼ƒï¼ˆå¤‰åŒ–ã‚’é‡è¦–ï¼‰
            if i > 0:
                prev_loudness = opensmile_data[i-1].get('features', {}).get('Loudness_sma3', 0)
                if loudness > prev_loudness * 1.3:
                    hint = "ç››ã‚Šä¸ŠãŒã‚Š"
                elif loudness < prev_loudness * 0.7:
                    hint = "è½ã¡ç€ã"
            
            # Jitterã¯äººã®å£°ã®ç‰¹å¾´ã¨ã—ã¦è§£é‡ˆ
            if jitter > 0.01:
                hint += " ç™ºè©±ã‚ã‚Š" if hint else "ç™ºè©±ã‚ã‚Š"
            elif jitter == 0:
                hint += " ç„¡éŸ³/ç’°å¢ƒéŸ³ã®ã¿" if not hint else "/ç„¡éŸ³"
                
            timeline_parts.append(f"{timestamp} | {loudness:.3f} | {jitter:.6f} | {hint}")
        
        prompt_parts.append("\n".join(timeline_parts))
        
        # çµ±è¨ˆæƒ…å ±
        if len(opensmile_data) > 0:
            loudness_values = [item.get('features', {}).get('Loudness_sma3', 0) for item in opensmile_data]
            jitter_values = [item.get('features', {}).get('jitterLocal_sma3nz', 0) for item in opensmile_data]
            
            avg_loudness = sum(loudness_values) / len(loudness_values)
            max_loudness = max(loudness_values)
            min_loudness = min(loudness_values)
            avg_jitter = sum(jitter_values) / len(jitter_values)
            max_jitter = max(jitter_values)
            
            prompt_parts.append(f"""
ã€60ç§’é–“ã®è¦ç´„ã€‘
- éŸ³å£°ã®å¤‰å‹•å¹…: {(max_loudness - min_loudness):.3f} ï¼ˆå¤‰å‹•ãŒå¤§ãã„ã»ã©æ„Ÿæƒ…ã®èµ·ä¼ã‚ã‚Šï¼‰
- ç™ºè©±ãŒã‚ã£ãŸæ™‚é–“: {len([j for j in jitter_values if j > 0])}ç§’ / {len(jitter_values)}ç§’
- ç„¡éŸ³ã¾ãŸã¯ç’°å¢ƒéŸ³ã®ã¿: {jitter_values.count(0)}ç§’
""")
    else:
        prompt_parts.append("""ã€éŸ³å£°ç‰¹å¾´ï¼ˆOpenSMILEï¼‰ã€‘
ãƒ‡ãƒ¼ã‚¿ãªã—
""")
    
    # SEDãƒ‡ãƒ¼ã‚¿ï¼ˆéŸ³éŸ¿ã‚¤ãƒ™ãƒ³ãƒˆï¼‰
    if sed_data:
        prompt_parts.append("""
ã€ç’°å¢ƒéŸ³ã®åˆ†æï¼ˆå‚è€ƒï¼‰ã€‘
â€»60ç§’é–“ã®éŒ²éŸ³ã‹ã‚‰æ¤œå‡ºã•ã‚ŒãŸç’°å¢ƒéŸ³ã§ã™ã€‚ç™ºè©±å†…å®¹ã®è§£é‡ˆã‚’è£œå®Œã™ã‚‹å‚è€ƒæƒ…å ±ã¨ã—ã¦ä½¿ç”¨ã—ã¦ãã ã•ã„ã€‚
""")
        
        # ç¾å®Ÿçš„ã§ãªã„éŸ³ã‚’ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
        unrealistic_keywords = ['Animal', 'Insect', 'Bird', 'Rodent', 'Mouse', 'Pig', 'Oink', 
                                'Roar', 'Howl', 'Bark', 'Meow', 'Cricket', 'Frog', 'Mosquito']
        
        # ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°å¾Œã®ã‚¤ãƒ™ãƒ³ãƒˆã‚’æŠ½å‡º
        filtered_events = []
        for event in sed_data:
            label = event.get('label', '')
            if not any(keyword.lower() in label.lower() for keyword in unrealistic_keywords):
                filtered_events.append(event)
        
        # ç¢ºç‡ã®é«˜ã„é †ã«ã‚½ãƒ¼ãƒˆ
        sorted_events = sorted(filtered_events, key=lambda x: x.get('prob', 0), reverse=True)
        
        # ä¸»è¦ãªéŸ³éŸ¿ã‚¤ãƒ™ãƒ³ãƒˆï¼ˆ70%ä»¥ä¸Šï¼‰
        high_prob_events = [e for e in sorted_events if e.get('prob', 0) >= 0.7]
        # ä¸­ç¨‹åº¦ã®éŸ³éŸ¿ã‚¤ãƒ™ãƒ³ãƒˆï¼ˆ40-70%ï¼‰
        mid_prob_events = [e for e in sorted_events if 0.4 <= e.get('prob', 0) < 0.7]
        
        # æ™‚ç³»åˆ—çš„ãªè§£é‡ˆã‚’æä¾›ï¼ˆç°¡æ½”ã«ï¼‰
        timeline_parts = []
        timeline_parts.append("ã€æ¤œå‡ºã•ã‚ŒãŸä¸»ãªç’°å¢ƒéŸ³ã€‘")
        timeline_parts.append("")
        
        # é‡è¦ãªéŸ³ã®ã¿è¡¨ç¤ºï¼ˆç¢ºç‡40%ä»¥ä¸Šï¼‰
        important_events = [e for e in sorted_events if e.get('prob', 0) >= 0.4][:10]
        
        if important_events:
            for event in important_events:
                label = event.get('label', 'Unknown')
                prob = event.get('prob', 0)
                # ç¢ºç‡ã«ã‚ˆã£ã¦é‡è¦åº¦ã‚’è¡¨ç¾
                if prob >= 0.7:
                    timeline_parts.append(f"  â— {label}: {prob*100:.1f}% ï¼ˆæ˜ç¢ºã«æ¤œå‡ºï¼‰")
                else:
                    timeline_parts.append(f"  â—‹ {label}: {prob*100:.1f}%")
        
        prompt_parts.append("\n".join(timeline_parts))
        
        # éŸ³éŸ¿ç’°å¢ƒã®ç·åˆçš„ãªè§£é‡ˆ
        prompt_parts.append(f"""
ã€ç’°å¢ƒéŸ³ã‹ã‚‰åˆ†ã‹ã‚‹ã“ã¨ã€‘
- äººã®å£°: {'æ¤œå‡ºã‚ã‚Š' if any('Speech' in e.get('label', '') or 'Child' in e.get('label', '') for e in sorted_events[:10]) else 'æ¤œå‡ºãªã—'}
- ç’°å¢ƒ: {'é¨’ãŒã—ã„' if any('Noise' in e.get('label', '') for e in sorted_events[:10]) else 'é™ã‹'}
- æ´»å‹•ã®æ´»ç™ºã•: {'æ´»ç™ºï¼ˆå¤šæ§˜ãªéŸ³ï¼‰' if len([e for e in sorted_events[:10] if e.get('prob', 0) > 0.4]) > 5 else 'ãŠã¨ãªã—ã„'}
""")
    else:
        prompt_parts.append("""ã€éŸ³éŸ¿ã‚¤ãƒ™ãƒ³ãƒˆï¼ˆYAMNetï¼‰ã€‘
ãƒ‡ãƒ¼ã‚¿ãªã—
""")
    
    # çµ±åˆçš„ãªæ™‚ç³»åˆ—è§£é‡ˆã‚»ã‚¯ã‚·ãƒ§ãƒ³
    if opensmile_data and sed_data:
        prompt_parts.append("""
ã€ç·åˆçš„ãªè§£é‡ˆã®ãƒã‚¤ãƒ³ãƒˆã€‘
â€»ç™ºè©±å†…å®¹ã‚’æœ€é‡è¦–ã—ã€éŸ³å£°ã®å¤‰åŒ–ãƒ‘ã‚¿ãƒ¼ãƒ³ã§å ´ã®é›°å›²æ°—ã‚’åˆ¤æ–­ã—ã¦ãã ã•ã„ï¼š

1. ç™ºè©±å†…å®¹ã‹ã‚‰ï¼šä½•ã‚’ã—ã¦ã„ãŸã‹ã€èª°ã¨è©±ã—ã¦ã„ãŸã‹
2. å£°ã®å¤‰åŒ–ã‹ã‚‰ï¼šç››ã‚Šä¸ŠãŒã£ã¦ã„ãŸã‹ã€è½ã¡ç€ã„ã¦ã„ãŸã‹
3. ç’°å¢ƒéŸ³ã‹ã‚‰ï¼šã©ã‚“ãªå ´æ‰€ã§ã€ã©ã‚“ãªæ´»å‹•ã‚’ã—ã¦ã„ãŸã‹

é‡è¦ï¼š
- å£°ã®å¤§å°ã®çµ¶å¯¾å€¤ã¯æ°—ã«ã—ãªã„ï¼ˆãƒã‚¤ã‚¯ã¨ã®è·é›¢ã®å•é¡Œï¼‰
- å£°ã®å¤‰åŒ–ãƒ‘ã‚¿ãƒ¼ãƒ³ï¼ˆå¤§ãããªã£ãŸ/å°ã•ããªã£ãŸï¼‰ã«æ³¨ç›®
- ç™ºè©±ãŒã‚ã‚‹æ™‚é–“å¸¯ï¼ˆJitter > 0ï¼‰ã«æ³¨ç›®
- ç¾å®Ÿçš„ã§ãªã„éŸ³éŸ¿ã‚¤ãƒ™ãƒ³ãƒˆã¯ç„¡è¦–
""")
    
    # åˆ†ææŒ‡ç¤ºï¼ˆæ™‚ç³»åˆ—åˆ†æã‚’é‡è¦–ï¼‰
    prompt_parts.append(f"""
âœ… ç·åˆåˆ†æã¨å‡ºåŠ›å½¢å¼

ä»¥ä¸‹ã®JSONå½¢å¼ã§ã€æ™‚ç³»åˆ—å¤‰åŒ–ã‚’è¸ã¾ãˆãŸåˆ†æçµæœã‚’è¿”ã—ã¦ãã ã•ã„ã€‚

**å‡ºåŠ›ä¾‹:**
```json
{{
  "time_block": "{time_block}",
  "summary": "è¦³æ¸¬å¯¾è±¡è€…ãŒä½•ã‚’ã—ã¦ã„ã¦ã€ã©ã‚“ãªæ°—æŒã¡ã ã£ãŸã‹ã€å ´ã®é›°å›²æ°—ã¯ã©ã†ã ã£ãŸã‹ã‚’2-3æ–‡ã§èª¬æ˜ã€‚æŠ€è¡“ç”¨èªã¯ä½¿ã‚ãšã€ç™ºè©±å†…å®¹ã‚’ä¸­å¿ƒã«å…·ä½“çš„ã«è¨˜è¿°",
  "vibe_score": -36,
  "confidence_score": 0.85,
  "temporal_analysis": {{
    "emotion_trajectory": "60ç§’é–“ã®æ„Ÿæƒ…ã®æµã‚Œï¼šå‰åŠã¯ç©ã‚„ã‹â†’ä¸­ç›¤ã§ç››ã‚Šä¸ŠãŒã‚Šâ†’å¾ŒåŠã¯è½ã¡ç€ã",
    "peak_moments": ["0:06ç§’ - å£°ãŒå¤§ãããªã£ãŸï¼ˆèˆˆå¥®ï¼‰", "0:23ç§’ - æ´»ç™ºã«è©±ã—ã¦ã„ã‚‹"],
    "quiet_periods": ["0:16-0:21ç§’ - ã»ã¼ç„¡éŸ³ï¼ˆä¼‘æ¯ã¾ãŸã¯è€ƒãˆä¸­ï¼‰"]
  }},
  "acoustic_features": {{
    "average_loudness": 0.186,
    "loudness_trend": "increasing/stable/decreasing",
    "voice_stability": "å®‰å®š/ã‚„ã‚„ä¸å®‰å®š/ä¸å®‰å®š",
    "notable_patterns": ["å£°ã®éœ‡ãˆãŒå¢—åŠ ï¼ˆç·Šå¼µã®å…†å€™ï¼‰"]
  }},
  "key_observations": [
    "æ™‚ç³»åˆ—ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰è¦³å¯Ÿã•ã‚ŒãŸé‡è¦ãªç‚¹1",
    "ç™ºè©±ã¨éŸ³éŸ¿ç‰¹å¾´ã®ç›¸é–¢ã‹ã‚‰åˆ¤æ˜ã—ãŸç‚¹2"
  ],
  "detected_mood": "neutral/positive/negative/anxious/relaxed/excited/tiredç­‰",
  "detected_activities": [
    "æ¨å®šã•ã‚Œã‚‹ä¸»ãªæ´»å‹•",
    "å‰¯æ¬¡çš„ãªæ´»å‹•"
  ],
  "context_notes": "æ™‚é–“å¸¯ã€éŸ³å£°ç‰¹å¾´ã®å¤‰åŒ–ãƒ‘ã‚¿ãƒ¼ãƒ³ã€ç’°å¢ƒéŸ³ã‹ã‚‰æ¨æ¸¬ã•ã‚Œã‚‹è©³ç´°ãªçŠ¶æ³"
}}
```

ğŸ” **åˆ†æã®é‡ç‚¹**
| è¦ç´  | æŒ‡ç¤ºå†…å®¹ |
|------|----------|
| **summary** | è¦³æ¸¬å¯¾è±¡è€…ãŒä½•ã‚’ã—ã¦ã„ãŸã‹ã€ã©ã‚“ãªæ°—æŒã¡ã ã£ãŸã‹ã€èª°ã¨ä½•ã‚’è©±ã—ã¦ã„ãŸã‹ã€‚æŠ€è¡“ç”¨èªã¯ä½¿ã‚ãšã€ç™ºè©±å†…å®¹ã‚’ä¸­å¿ƒã«å…·ä½“çš„ã«è¨˜è¿° |
| **vibe_score** | -100ã€œ+100ã®æ•´æ•°å€¤ã€‚å ´ã®ç››ã‚Šä¸ŠãŒã‚Šã€ãƒ†ãƒ³ã‚·ãƒ§ãƒ³ã®é«˜ä½ã‚’æ•°å€¤åŒ–ã€‚ç™ºè©±å†…å®¹ã¨å£°ã®å¤‰åŒ–ãƒ‘ã‚¿ãƒ¼ãƒ³ã‹ã‚‰åˆ¤æ–­ |
| **æ„Ÿæƒ…ã®æ¨ç§»** | 60ç§’é–“ã§ã®æ„Ÿæƒ…ã‚„ãƒ†ãƒ³ã‚·ãƒ§ãƒ³ã®å¤‰åŒ–ã€‚å£°ãŒå¤§ãããªã£ãŸ/å°ã•ããªã£ãŸã€ç››ã‚Šä¸ŠãŒã£ãŸ/è½ã¡ç€ã„ãŸãªã©å¤‰åŒ–ã«æ³¨ç›® |
| **confidence_score** | åˆ†æã®ç¢ºä¿¡åº¦ã€‚ç™ºè©±ãŒæ˜ç¢ºã§éŸ³å£°ãƒ‡ãƒ¼ã‚¿ãŒè±Šå¯Œãªã‚‰é«˜ã |
| **temporal_analysis** | 60ç§’é–“ã®ä¸­ã§ã®å¤‰åŒ–ã‚’è¨˜è¿°ã€‚ã€Œå‰åŠã€ã€Œä¸­ç›¤ã€ã€Œå¾ŒåŠã€ã§ä½•ãŒèµ·ããŸã‹ |
| **key_observations** | ç™ºè©±å†…å®¹ã‹ã‚‰åˆ†ã‹ã‚‹å…·ä½“çš„ãªè¡Œå‹•ã‚„æ„Ÿæƒ…ã‚’è¨˜è¼‰ |

ğŸ“Š **ã‚¹ã‚³ã‚¢ãƒªãƒ³ã‚°æŒ‡ç¤º**
- **-100ã€œ+100ã®å…¨ç¯„å›²ã‚’ç©æ¥µçš„ã«ä½¿ç”¨ã—ã¦ãã ã•ã„**
- ã‚¹ã‚³ã‚¢åˆ†å¸ƒã®ç›®å®‰ï¼š
  * éå¸¸ã«ãƒã‚¸ãƒ†ã‚£ãƒ–: 60ã€œ100
  * ãƒã‚¸ãƒ†ã‚£ãƒ–: 20ã€œ60  
  * ãƒ‹ãƒ¥ãƒ¼ãƒˆãƒ©ãƒ«: -20ã€œ20
  * ãƒã‚¬ãƒ†ã‚£ãƒ–: -60ã€œ-20
  * éå¸¸ã«ãƒã‚¬ãƒ†ã‚£ãƒ–: -100ã€œ-60
- ä»¥ä¸‹ã®è¦ç´ ã§åŠ ç‚¹/æ¸›ç‚¹ï¼š
  * éŸ³é‡ãŒå¤§ãã„æ™‚é–“å¸¯: +10ã€œ20
  * å£°ã®éœ‡ãˆãŒå¤šã„: -10ã€œ30
  * é•·ã„æ²ˆé»™: -5ã€œ15
  * æ´»ç™ºãªä¼šè©±: +15ã€œ25
  * æ—©æœã®æ´»å‹•: +20ã€œ30
  * æ·±å¤œã®æ´»å‹•: -20ã€œ30ï¼ˆå†…å®¹ã«ã‚ˆã‚‹ï¼‰

**JSONã®ã¿ã‚’è¿”ã—ã¦ãã ã•ã„ã€‚èª¬æ˜ã‚„è£œè¶³ã¯ä¸€åˆ‡ä¸è¦ã§ã™ã€‚**
""")
    
    return "\n".join(prompt_parts)


async def save_prompt_to_dashboard(supabase_client, device_id: str, date: str, time_block: str, prompt: str):
    """
    ç”Ÿæˆã—ãŸãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’dashboardãƒ†ãƒ¼ãƒ–ãƒ«ã«ä¿å­˜
    """
    try:
        data = {
            'device_id': device_id,
            'date': date,
            'time_block': time_block,
            'prompt': prompt,
            'updated_at': datetime.now().isoformat()
        }
        
        result = supabase_client.table('dashboard').upsert(data).execute()
        print(f"âœ… Prompt saved to dashboard table for {time_block}")
        return True
    except Exception as e:
        print(f"Error saving prompt to dashboard: {e}")
        traceback.print_exc()
        return False


async def process_and_save_to_dashboard(supabase_client, device_id: str, date: str, time_block: str, 
                                       summary: str = None, vibe_score: float = None):
    """
    å‡¦ç†çµæœã‚’dashboardãƒ†ãƒ¼ãƒ–ãƒ«ã«ä¿å­˜
    """
    try:
        data = {
            'device_id': device_id,
            'date': date,
            'time_block': time_block,
            'updated_at': datetime.now().isoformat()
        }
        
        # NULLã‚’è¨±å¯ã™ã‚‹ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã¯å€¤ãŒã‚ã‚‹å ´åˆã®ã¿è¿½åŠ 
        if summary is not None:
            data['summary'] = summary
        if vibe_score is not None:
            data['vibe_score'] = vibe_score
        
        result = supabase_client.table('dashboard').upsert(data).execute()
        return True
    except Exception as e:
        print(f"Error saving to dashboard: {e}")
        traceback.print_exc()
        return False


# ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆç”¨ã®å‡¦ç†é–¢æ•°


async def process_timeblock_v2(supabase_client, device_id: str, date: str, time_block: str) -> Dict[str, Any]:
    """
    å‡¦ç†: Whisper + SEDãƒ‡ãƒ¼ã‚¿ï¼ˆbehavior_yamnetãƒ†ãƒ¼ãƒ–ãƒ«ä½¿ç”¨ï¼‰+ OpenSMILEãƒ‡ãƒ¼ã‚¿ + è¦³æ¸¬å¯¾è±¡è€…æƒ…å ±
    """
    # ãƒ‡ãƒ¼ã‚¿å–å¾—
    transcription = await get_whisper_data(supabase_client, device_id, date, time_block)
    sed_data = await get_sed_data(supabase_client, device_id, date, time_block)
    opensmile_data = await get_opensmile_data(supabase_client, device_id, date, time_block)
    subject_info = await get_subject_info(supabase_client, device_id)
    
    # ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆç”Ÿæˆï¼ˆOpenSMILEãƒ‡ãƒ¼ã‚¿ã‚‚å«ã‚ã¦æ¸¡ã™ï¼‰
    prompt = generate_timeblock_prompt(transcription, sed_data, time_block, date, subject_info, opensmile_data)
    
    # ãƒ‡ãƒãƒƒã‚°ç”¨ï¼šå–å¾—ã—ãŸãƒ‡ãƒ¼ã‚¿ã®æƒ…å ±ã‚’å‡ºåŠ›
    print(f"ğŸ“Š Data retrieved for {time_block}:")
    print(f"  - Transcription: {'Yes' if transcription else 'No'} ({len(transcription) if transcription else 0} chars)")
    print(f"  - SED Events: {'Yes' if sed_data else 'No'} ({len(sed_data) if sed_data else 0} events)")
    print(f"  - OpenSMILE Timeline: {'Yes' if opensmile_data else 'No'} ({len(opensmile_data) if opensmile_data else 0} seconds)")
    print(f"  - Subject Info: {'Yes' if subject_info else 'No'}")
    
    # ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆä¿å­˜ï¼ˆdashboardãƒ†ãƒ¼ãƒ–ãƒ«ã¸ï¼‰
    await save_prompt_to_dashboard(supabase_client, device_id, date, time_block, prompt)
    
    return {
        "status": "success",
        "version": "v3",  # ãƒãƒ¼ã‚¸ãƒ§ãƒ³ã‚’v3ã«æ›´æ–°
        "device_id": device_id,
        "date": date,
        "time_block": time_block,
        "prompt": prompt,  # ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’è¿”ã‚Šå€¤ã«è¿½åŠ 
        "prompt_length": len(prompt),
        "has_transcription": transcription is not None and len(transcription.strip()) > 0,
        "has_sed_data": sed_data is not None and len(sed_data) > 0,
        "has_opensmile_data": opensmile_data is not None and len(opensmile_data) > 0,
        "sed_events_count": len(sed_data) if sed_data else 0,
        "opensmile_seconds": len(opensmile_data) if opensmile_data else 0
    }